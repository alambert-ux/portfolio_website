---
date: "2017-10-31T21:28:43-05:00"
description: "What Clusters of BBC iPlayer Users Exist and How Can We Recommend them Suitable Films?"
draft: false
image: pic04.jpg  
keywords: ""
slug: scorsese
title: Scorsese

---

# **What Clusters of BBC iPlayer Users Exist and How Can We Recommend them Suitable Films?**

## **Applying Unsupervised Machine Learning Approaches to Segment Users and Recommend Movies**

---

# Executive Summary 

The full reports for this project can be viewed as PDFs. See [Report 1](https://drive.google.com/file/d/1zxEOp_or8kaDXiYRs5ARM7F1FrVlhBeb/view?usp=sharing "Applying Cluster Analysis to Segment BBC iPlayer Users") for analysis of targetable clusters of BBC iPlayer users, and [Report 2](https://drive.google.com/file/d/1Xw5V0KCXi2RPeYuUyy7tVp-KKxfpIFZS/view?usp=sharing "Building and Evaluating Movie Recommendation Systems") for a step-by-step summary of the recommendation system construction and optimisation process.

# The Problem  

Intense competition for our finite attention has created a booming industry driven by 'engagement', seeking to hold our attention for long enough to monetize it through advertising or increased retention, and thus increased lifetime value to the platform. 

Machine learning lies at the core of methodologies designed to identify, segment and target these users, keeping their eyes on the screen for as long as possible. 

**The problem is therefore twofold:** 

**Firstly:** How can we identify which types of users exist on the platform, and target advertisement to their individual character profiles to *maximise ad revenue*?"

**Secondly:** How can we ensure our content recommendations are of a high quality in order to *maximise customer engagement, and thus customer lifetime value* to the platform?

**To address each, I:**

**I)** employ Cluster Analysis, an *unsupervised learning approach*, on a rich BBC iPlayer dataset to identify user profiles for targeted product and service advertising (under the assumption that this *is* a platform which advertises to its users)

**II)** subsequently employ a multitude of *unsupervised* Collaborative Filtering (CF) approaches trained on IMDB movie rating data, in order to build an effective movie recommendation system for integration into the BBC iPlayer platform

# The Data

This investigation applies three key datasets: the **first** is of almost 94,000 BBC iPlayer users, across almost 20 characteristics, including genres watched, total viewing duration, average proportion of programs viewed, and most common viewing time; the **second** is a dataset of approximately 9,750 movies rated on IMDB, classified by genre; and the **third** is a dataset of 101,000 individual ratings given by IMDB users to these 9750 movies. While the first dataset is sufficient to identify clusters of BBC iPlayer users with an unsupervised learning approach, a combination of the second and third databases is necessary to build a ratings matrix suitable for construction of a movie recommendation system. 

Note that IMDB data is used instead of BBC iPlayer movie data because iPlayer does not allow rating of its movies. Since the Recommendation System must be trained on a large ratings matrix, the world's largest movie ratings database is the logical source. Of course, this also means that the Recommendation System will not be directly applicable to the BBC case, and a proxy ratings system will be required unless the BBC chooses to deploy a ratings feature in their iPlayer application. A reasonable proxy rating would for example be established via a composite measure considering: whether a certain type of user watched the movie at their "prime time"; whether the movie was completed; whether the movie was rewatched; whether it was reshared; how often it was paused, i.e. whether it was watched in a single sitting, and so on.

# The Solution

The following analyses first (I) specify and evaluate key clusters of BBC iPlayer users to be targeted with tailored advertisement, and subsequently (II) build an optimal item-based collaborative filtering movie recommendation system (with matrix factorisation) to boost engagement and therefore customer lifetime value (CLV). 

## I/II. What Clusters of BBC iPlayer Users Exist?

I focus specifically on the three clusters generated by the full-sample k-means clustering approach with k=3, since this seems most consistent with my selection criteria. Note however that both the PAM and Hierarchical (Ward) approaches ratify the substantive existence of these clusters. 

**The “Family”, Cluster 2**  
  
  Both the k-means and hierarchical clustering (Ward method) methodologies (Figures 7 to 9), identified a cluster of “Family” BBC iPlayer viewers with a strong preference for Children’s and Learning content and relatively high engagement during the Daytime, and particularly in the Afternoon. This is consistent with a conception of accounts used mainly when children return home from school and either watch children’s shows or learning programs. Given the stability of this cluster’s centers and principal components between the most effective clustering methodologies and across the sample and both subsamples, this profile is the most robust (and thereby plausible) cluster. 

**The “Working Professional”, Cluster 1**  
  
  Though with less certainty, since this cluster is less stable across subsamples and clustering methodologies, I identify a cluster of viewers with relatively high engagement who have a propensity towards Drama, Comedy and Entertainment shows in the Evening and Nighttime. This seems consistent with adult viewers who work during the day and use BBC iPlayer to de-stress with films and series after work. Though not particularly pronounced in the k-means clusters, this cluster is clearly identifiable as Cluster 2 in the PAM methodology, which implies it is somewhat plausible.  

**The “Daytime Viewer”, Cluster 3**  
  
  Finally, I distinguish a cluster of viewers that tend to watch BBC iPlayer during the day, and largely watch News, Factual, Sport and Weather genres with low engagement. This cluster is consistent with profiles of elderly and unemployed viewers who are at home during the day but like to stay informed. Although this cluster does not stand out particularly in the k-means method, it is pronounced in the cluster center plots of both the PAM (where it is represented by Cluster 1) and Hierarchical (Ward) method (represented by Cluster 2), suggesting that it too is a plausible segment.

**Content Recommendations Notifications to Boost Viewer Engagement**  
  
  For example, if a viewer mainly watches Children’s shows, then the BBC iPlayer app should send them notifications of recommended Children’s and Learning shows during the afternoon, since this is the time when this “Family” viewer is most likely to watch. Similarly, if a viewer mainly watches daytime News and Weather shows, notifications should be sent in the morning and recommend Sports, cross-selling other genres that the “Daytime Viewer” profile has a tendency to consume. 

**Targeted Advertisement to Boost Advertising Revenues (…if iPlayer Enabled Advertisement)**  
  
  At present BBC iPlayer does not allow third party advertisements, however, if it did, then these distinct viewer profiles would prove invaluable for targeting. For example, if a viewer mostly watches news during the day, I can expect that they are either retired or unemployed and target them with services such as holidays, loans and insurance. Alternatively, viewers who watch dramas in the evening can be targeted with products such as alcohol, fast food, cosmetics and cars. 

## II/II. How Can We Recommend Them Suitable Films?

Of the three recommendation model specifications evaluated, LIBMF minimises RMSE regardless of the prevalence of ratings associated with the users and movies it is trained on. This model-based matrix factorisation collaborative filtering approach consists of decomposing the sparse user-item interaction matrix into a product of two smaller, more densely populated matrices representing latent variable representations for users and movies, respectively.  Resultingly, close users in terms of movie preferences, as well as close movies in terms of characteristics, are assigned close representations in the latent space. Specifically, of the 15 models surveyed, I recommend use of LIBMF trained on ratings from users and movies which have given or received at least 50 ratings, since this is when RMSE is minimised. Under the assumption that there are no more than 10 latent variables (factors, such as genre) describing movie ‘types’, which can be used to describe user preferences, I set dimensions to 10. 

# **Analysis in R**

---

# **I/II. What Clusters of BBC iPlayer Users Exist?**

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(cluster)
library(Hmisc)
library(factoextra)
library(purrr)
library(gridExtra)
library(skimr)
library(ggthemes)
library(patchwork) 
library(rsample)
library(dplyr)
library(recommenderlab)
library(ggplot2)
library(data.table)
library(reshape2)
library(janitor)
library(kableExtra)

```

```{r setup2, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

It is particularly important to know which customer segments are interested in what content and how this drives their engagement with the BBC (often measured by how happy they are to pay for the TV licensing fees).

# Cleaned Data

As the original view data is already processed and cleaned, I now generate a user-based database which I will use to train clustering algorithms to identify meaningful clusters in the data.

Let's load the cleaned data and investigate what's in the data. See below for column descriptions.

```{r Load_data, message=FALSE, warning=FALSE}
cleaned_BBC_Data <- read_csv(here::here('data','Results_Step1.csv'))

glimpse(cleaned_BBC_Data) 
```

The column descriptions are as follows.

a)	user_id  -- a unique identifier for the viewer

b)	program_id and series_id -- these identify the program and the series that the program belongs to

c)	genre -- the programme’s genre (e.g., drama, factual, news, sport, comedy, etc)

d)	start_date_time -- the streaming start date/time of the event

e)	Streaming id -- a unique identifier per streaming event

f)	prog_duration_min -- the program duration in minutes

g)	time_viewed_min -- how long the customer watched the program in minutes

h)  duration_more_30s - equals 1 if the program duration is more than 30 seconds, equals 0 otherwise 

h)  time_viewed_more_5s - equals 1 if time_viewed is more than 5 seconds, equals 0 otherwise

i)  percentage_program_viewed -- percantage of the program viewed

j) watched_more_60_percent -- equals 1 if more than 60% of the program is watched, equals 0 otherwise

k) month, day, hour, weekend -- timing of the viewing

l) time_of_day -- equals “Night” if the viewing occurs between 22 and 6am, "Day" if it occurs between 6AM and 14, “Afternoon” if the it occurs between 14 and 17, “Evening” otherwise

Before I proceed let's consider the usage in January only.

```{r filter_data, message=FALSE, warning=FALSE}

cleaned_BBC_Data<-filter(cleaned_BBC_Data,month==1)

```

# User based data

I will try to create meaningful customer segments that describe users of the BBC iPlayer service. First I need to change the data to user based and generate a summary of their usage. 

## Data format

The data is presented to us in an event-based format (every row captures a viewing event). However I need to detect the differences between the general watching habits of users. To do so, I need to come up with variables to capture these differences.

## Feature Engineering

First, let’s generate the following variables for each user.

i.	Total number of shows watched and ii.	Total time spent watching shows on iPlayer by each user in the data

```{r total_number_shows&time, message=FALSE, warning=FALSE}

userData<-cleaned_BBC_Data %>% group_by(user_id) %>% summarise(noShows=n(), total_Time=sum(time_viewed_min)) 

```

iii.	Proportion of shows watched during the weekend for each user.

```{r percentage_weekend , message=FALSE, warning=FALSE, results='hide'}

#Let's find the number of shows on weekend and weekdays
userData2<-cleaned_BBC_Data %>% group_by(user_id,weekend) %>% summarise(noShows=n())

#Let's find percentage in weekend and weekday
userData3 = userData2%>% group_by(user_id) %>% mutate(weight_pct = noShows / sum(noShows))

#Let's create a data frame with each user in a row.
userData3<-select (userData3,-noShows)
userData3<-userData3%>% spread(weekend,weight_pct,fill=0) %>%as.data.frame()
#Let's merge the final result with the data frame from the previous step.
userdatall<-left_join(userData,userData3,by="user_id")

```

iv.	Proportion of shows watched during different times of day for each user.

```{r percentage_time_day, message=FALSE, warning=FALSE, results='hide'}

#Code in this block follows the same steps above.
userData2<-cleaned_BBC_Data %>% group_by(user_id,time_of_day) %>% summarise(noShows=n()) %>% mutate(weight_pct = noShows / sum(noShows))

userData4<-select (userData2,-c(noShows))
userData4<-spread(userData4,time_of_day,weight_pct,fill=0)

userdatall<-left_join(userdatall,userData4,by="user_id")

```

> The proportion of shows watched in each genre by each user.

```{r percentage_genre , message=FALSE, warning=FALSE}

userData5 <- cleaned_BBC_Data %>% 
  group_by(user_id, genre) %>% 
  summarise(count=n()) %>% 
  mutate(total= sum(count), genre_proportion=((count/total))) %>% 
  select(-c(3,4)) %>% 
  pivot_wider(names_from="genre",values_from="genre_proportion") # could use spread alternatively

userdatall<-left_join(userdatall,userData5,by="user_id")

```

> One more variable: Average percentage program viewed for each user 

```{r add_one_more_variable, results='hide', message=FALSE, warning=FALSE}

#DIFFERENTIATING BETWEEN "HIGH ENGAGEMENT" AND "LOW ENGAGEMENT" USERS

#option 1

userData6 <- cleaned_BBC_Data %>% 
  group_by(user_id) %>% 
  summarise(mean_percentage_viewed=mean(percentage_program_viewed))
  
userdatall<-left_join(userdatall,userData6,by="user_id")

```
 
The average percentage program viewed is useful as a proxy for user engagement. Specifically, I seek to differentiate between users who are served content which they engage with (i.e. watch the majority of), and those who are less likely to engage with the content they watch (watch consistently low proportions of each show on average). 
 
# Visualizing user-based data

Next I visualize the information captured in the user based data. Let's start with the correlations.

```{r correlations, message=FALSE, warning=FALSE, results='hide', fig.height=10, fig.width=10}

library("GGally")
userdatall %>% 
  select(-user_id) %>% #keep Y variable last
  ggcorr(method = c("pairwise", "pearson"), layout.exp = 3,label_round=2, label = TRUE,label_size = 2,hjust = 1)+
  labs(subtitle="There is a strong correlation between some variables such as learning & no genre, weekend & weekday", title= "Correlation Table")

```

Most correlated variables are:

- Learning and NoGenre (cor = 1)
- Weekend and weekday (cor = -1)

In addition, the following variables worth highlighting:
- RelEthics and NoGenre (cor = 0.97)
- noShows and total_Time (cor = 0.92)

The implication for this is as follows: These correlated variables will generate predictable patterns in cluster centres (for instance, means). This means there is some redundancy in the data, since by identifying a cluster centre for one variable of the correlated pair, I are able to predict the cluster centre for the other. Thus, I could reduce the number of dimensions without losing information by dropping one of the correlated variables, which would result in more meaningful clusters, however this input may result in some distance being artificially changed, thus would require careful post-evaluation.

> Distribution of noShows and total_Time visualized with box-whisker plots and histograms.

```{r box_whisker_histogram, fig.height=10, fig.width = 10, fig.align="centre", message=FALSE, warning=FALSE}

userdatall_plots <- userdatall %>% 
  mutate(mean_noShows=mean(noShows), median_noShows=median(noShows),mean_time=mean(total_Time), median_time=median(total_Time))

p1 <- ggplot(userdatall_plots, aes(x=as.numeric(total_Time)))+
  geom_boxplot(alpha=0.1)+
  scale_x_continuous(limits = c(0,300))+ # I do want to see where first outliers appear
  labs(x ="Total Time (minutes)", title= "Distribution of Total Time Watched") + theme_fivethirtyeight() + theme(axis.title=element_text(), axis.text.y = element_blank(),
         axis.ticks.y = element_blank())

p2 <- ggplot(userdatall_plots, aes(x=as.numeric(noShows)))+
   geom_boxplot(alpha=0.1)+
  scale_x_continuous(limits = c(0,50))+ # I do want to see where first outliers appear
  labs(x ="Number of Shows", title= "Distribution of Number of Shows")+
  theme_fivethirtyeight() + theme(axis.title=element_text(), axis.text.y = element_blank(),
         axis.ticks.y = element_blank())

p3 <- ggplot(userdatall_plots, aes(x=as.numeric(total_Time)))+
  geom_histogram()+
  scale_x_log10() +
  labs(x ="Total Time (minutes)",y="Count") + theme_fivethirtyeight() + theme(axis.title=element_text()) +
    geom_vline(xintercept=userdatall_plots$mean_time, size=0.5, color="red") + annotate(geom = 'text', colour= "white", label = "Sample Mean", x = userdatall_plots$mean_time+100, y = 450, angle=270) + geom_vline(xintercept=userdatall_plots$median_time, size=0.5, color="blue") + annotate(geom = 'text', colour= "white", label = "Sample Median", x = userdatall_plots$median_time+30, y = 420, angle=270)


p4 <- ggplot(userdatall, aes(x=as.numeric(noShows)))+
  geom_histogram()+
  scale_x_log10() +
  labs(x = "Number of Shows",y="Count") +
   theme_fivethirtyeight() + theme(axis.title=element_text()) + 
  geom_vline(xintercept=userdatall_plots$mean_noShows, size=0.5, color="red") + annotate(geom = 'text', label = "Sample Mean", x = userdatall_plots$mean_noShows+3, y = 1800, angle=270) + geom_vline(xintercept=userdatall_plots$median_noShows, size=0.5, color="blue") + annotate(geom = 'text', label = "Sample Median", x = userdatall_plots$median_noShows+1, y = 1700, angle=270)

(p1 + p3) /( p2 + p4)

```

Number of shows and total time watched are both heavily positively skewed (median>mean): the former has a mode of only one show watched, whereas most people spend around 100 minutes watching shows on BBC iPlayer in the researched period. This strong skew reflects the influence of outliers at the upper limit of both variables, which are observed in the box-and-whisker plots. 

These outliers can have significant impact on the structure of clusters, and in order to reduce this impact, I will employ a log transformation. 

## Delete infrequent users

I delete the records for users whose total view time is less than 5 minutes and who views 5 or fewer programs. These users are not very likely to be informative for clustering purposes. Or I can view these users as a ``low-engagement'' cluster. 

```{r delete, message=FALSE, warning=FALSE, fig.height=5, fig.width=10}

userdata_red<-userdatall%>%filter(total_Time>=5)%>%filter(noShows>=5)
ggplot(userdata_red, aes(x=total_Time)) +geom_histogram(binwidth=25)+labs(x="Total Time Watched (mins)", y= "Count", title="Distribution of Total Time Watched Without Low-Engagement Users")
glimpse(userdata_red)

```

# Clustering with K-Means

Now I are ready to find clusters in the BBC iPlayer viewers. I will start with the K-Means algorithm.

## Training a K-Means Model

To train a K-Means model, I start with 2 clusters and I de-select `user_id` variable. Also I scale the data. I use 50 random starts. I could use more starts, but 50 starting points should be enough to get a accurate result.

```{r fit_kmean_k2, message=FALSE, warning=FALSE, fig.height=7, fig.width=7}

set.seed(1) # set seed for reproducibility

k=2
n=50

# Get rid of variables that I might not need. Do not include no shows as well because it is highly correlated with total time

userdata_sel <- userdata_red %>%
  select(-c(user_id, weekday, noShows, NoGenre)) %>%  # drop one of each of the highly correlated variables and userID
  mutate(total_Time = log1p(total_Time)) #applying a log transfomation in order to reduce the impact of outliers

#skim(userdata_sel) 

userdata_sel[is.na(userdata_sel)] = 0 #change NA to 0 (NAs appear only in genre percentages)

userdata_sel<-data.frame(scale(userdata_sel)) #scale the data

#sanity check for scaling data

print(mean(userdata_sel$total_Time)) 

print(sd(userdata_sel$total_Time))
  
#train k-means clustering (and display cluster sizes via graph=TRUE)

model_kmeans_2clusters<-eclust(userdata_sel, "kmeans", k = 2,nstart = 50, graph = TRUE)

#check components
summary(model_kmeans_2clusters) 

#obtain the size of the clusters
model_kmeans_2clusters$size

# add clusters info the data frame
userdata_sel_clusters<-mutate(userdata_sel, cluster = as.factor(model_kmeans_2clusters$cluster))

```

There are two clusters of following sizes: 2381 and 1244. There is no need to increase the number of starts, since cluster sizes do not change when I do so (i.e. cluster sizes are not sensitive to increases in the number of starts from 50 to 100, to 150). 

## Visualizing the results

### Cluster centers 

I plot the normalized cluster centers and describe the clusters that the algorithm suggests. 

```{r cluster_centers, fig.height=10, fig.width=15, fig.align="centre", message=FALSE, warning=FALSE}

#new data frame with cluster centers and cluster numbers
cluster_centers<-data.frame(cluster=as.factor(c(1:2)),model_kmeans_2clusters$centers)

#transpose this data frame
cluster_centers_t<-cluster_centers %>% gather(variable,value,-cluster,factor_key = TRUE)

#plot the centers for k=2
graphkmeans_2clusters<-ggplot(cluster_centers_t, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "Cluster 1: Spend More Time Watching BBC iPlayer and Watch More Drama and Comedy Shows, Particularly in the Evening and at Night with Higher Engagement \nCluster 2: Spend Less Time Watching BBC iPlayer, Have Broader Tastes and Watch Mainly News and Children's TV Genres in the Afternoon and Daytime with Lower Engagement", title="K-means Cluster Centers, k=2", x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

graphkmeans_2clusters

```
I generated two clusters, whose main differentiators are viewing habits and engagement (average percentage of content viewed), rather than the watched content. 

**Cluster 1**
Cluster 1 represents viewers that spend more time watching BBC iPlayer, are more engaged (on average watch a higher percentage of the content they view), and mainly watch shows during the evening, night and weekends. In addition, in terms of content, they tend to watch more drama, comedy and entertainment shows. 

The viewer profile for Cluster 1 could be the adult viewer watching to relax during the evenings after work, and on weekends. 

**Cluster 2**
Cluster 2 is effectively the opposite of Cluster 1 in their watching behaviour. They they spend less time watching BBC iPlayer, are less engaged with the content (watch a lower percentage of the content they view, on average), and mostly watch during daylight (day, afternoon). In terms of content, they tend to watch predominantly cotent for children, learning, and News genres, and engage with a much broader spectrum of genres than the Cluster 1 viewer. 

The viewer profile that comes to mind for Cluster 2 is the family household viewer, split between daytime children shows and news. 
**Leveraging Clusters to Improve the Viewer Experience**

These clusters are somewhat meaningful, however the limits of 2 clusters mean that I cannot distinguish more types of users interested in particular content/genres. 

However, this does allow us to make speculative efforts to improve the viewer experience by suggesting a relationship between viewing habits and a few genres. In particular, I expect that recommending shorter shows such as news or children's shows that do not require much attention from users might increase viewer experience during the day, and suggest more complex or longer shows (more demanding in terms of attention and time) during evening/night time.

### Clusters vs variables

I plot a scatter plot for the viewers with respect to total_Time and weekend variables with color set to the cluster number of the user. 

```{r distribution_wrt_variables, fig.height=7, fig.width=10, fig.align="centre"}

ggplot(userdata_sel_clusters, aes(x = total_Time, y = weekend, color =  as.factor(cluster))) +
  geom_jitter(alpha=0.8)+labs(color = "Cluster", x="Total Time",y="Weekend", title="Total Time Watched has a Strong Impact on Determining Clusters of Viewers", subtitle="Heterogeneity Across Weekend Viewing and Total Viewing Time Variables Between Clusters") + theme_fivethirtyeight() + theme(axis.title=element_text())

```
I do observe that most of points are located in the lower part of the graph, which suggests that the Weekend variable is not that crucial in determining clusters. Evidently, total_Time plays a more prominent role, since points are more dispersed along the x-axis, with Cluster 1 appearing to have a higher average level of total_Time than Cluster 2. 

### Clusters vs PCA components

Repeat the previous step and use the first two principle components using `fviz_cluster` function.

```{r cluster_centers2, fig.height=10, fig.width=15, fig.align="centre",  message=FALSE, warning=FALSE}

fviz_cluster(model_kmeans_2clusters, userdata_sel, palette = "Set2", main="K-Means Cluster Plot Across Two Principal Components",subtitle="All Variables are Log Transformed to Mitigate the Effect of Outliers", x="Dimension 1 (10.9%)", y="Dimension 2 (9.6%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

```

As the plot of cluster centres previously suggested, there is no clear distinction between clusters, since they overlap when visualised in terms of the first two principal components. 

### Clusters vs PCA components without log transform

As a robustness check, I use K-means method again but this time do not log transform `total time` and include `no_shows`. 

```{r cluster_centers_without_log_transform, fig.height=10, fig.width=15, fig.align="centre",  message=FALSE, warning=FALSE}

userdata_selv2 <- userdata_red %>%
  select(-c(user_id, weekday, NoGenre))  # drop one of high correlated variables and userID

#skim(userdata_sel) 

userdata_selv2[is.na(userdata_selv2)] = 0 #change NA to 0 (NAs appear only in genre percentages)

userdata_selv2<-data.frame(scale(userdata_selv2)) #scale the data

set.seed(1) # set seed for reproducibility

#train kmeans clustering

model_kmeans_2clustersv2<-eclust(userdata_selv2, "kmeans", k = 2,nstart = 50, graph = TRUE)

#Size of the clusters

model_kmeans_2clustersv2$size

#Plot centers for k=2

#new data frame with cluster centers and cluster numbers
cluster_centers2<-data.frame(cluster=as.factor(c(1:2)),model_kmeans_2clustersv2$centers)

#transpose this data frame
cluster_centers2_t<-cluster_centers2 %>% gather(variable,value,-cluster,factor_key = TRUE)

#plot the centers
ggplot(cluster_centers2_t, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "Cluster 1: Spend More Time Watching BBC iPlayer and Watch More Drama and Comedy Shows, Particularly in the Evening and at Night with Higher Engagement \nCluster 2: Spend Less Time Watching BBC iPlayer, Have Broader Tastes and Watch Mainly News and Children's TV Genres in the Afternoon and Daytime with Lower Engagement", title="K-means Cluster Centers, k=2", x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Number of Shows", "Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

#PCA visualization
fviz_cluster(model_kmeans_2clustersv2, userdata_selv2, palette = "Set2", main="K-Means Cluster Plot Across Two Principal Components",subtitle="Variables are Not Log Transformed", x="Dimension 1 (11.1%)", y="Dimension 2 (10.1%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

```

**Cluster Sizes**

There is a significant difference in terms of cluster sizes between the non-log-transformed (3444, 182) and log-transformed (2381, 1244) partitions. 

**Plotting Centers**

The clustering without log transformation is less meaningful than when variables are log transformed, since the Cluster 1 center has values approximately to zero for almost all variables. This is because of a number of outliers which bias each Cluster. Due to this bias, the k-means algorithm is unable to differentiate Cluster 1 sufficiently well from Cluster 2, as it is when the log transformation is applied. 

**Principal Components**

The PCA plot emphasises the presence of outliers, which are accountable for an even greater overlap between clusters and lack of distinct variable traits in the Cluster 1 centre. 

## Elbow Chart

I use an elbow chart to identify a reasonable range for the number of clusters. 

```{r elbow, message=FALSE, warning=FALSE, fig.height=5, fig.width=10}

fviz_nbclust(userdata_sel,kmeans,k.max = 20, method = "wss") +
  labs(title="Optimal Number of Clusters", subtitle = "Elbow Method", x="Number of Clusters, k", y="Total Within Sum of Squares") + theme_fivethirtyeight() + theme(axis.title = element_text()) + scale_y_continuous(breaks=seq(25000,65000,5000), limits=c(25000,65000)) + geom_vline(xintercept=13, size=0.5, color="red") + geom_vline(xintercept=17, size=0.5, color="red")

```

From the plot above, I observe an elbow shape when k = 13, where the reduction in total within sum of squares becomes considerably smaller than when k = 12, suggesting that I need at least 13 clusters in order not to miss out on a considerable reduction in total within sum of squares. Further, starting from k = 17, the marginal reduction seems to be minor as k increases. Therefore, 13 to 17 could be a good range for the number of clusters in my case.

## Silhouette method

As another robustness check, I also use the silhouette method to identify a reasonable range for the number of clusters. 

```{r silhouette, message= FALSE, warning=FALSE, fig.height=5, fig.width=10}

fviz_nbclust(userdata_sel, kmeans, method = "silhouette",k.max = 20)+labs(title="Optimal Number of Clusters", subtitle = "Silhouette Method", x="Number of Clusters, k", y="Average Silhouette Width") + theme_fivethirtyeight() + theme(axis.title = element_text()) + scale_y_continuous(breaks=seq(0,0.20,0.05), limits=c(0,0.20))

```
The silhouette plot recommends k = 13 as the optimal number of clusters for my analysis. This is because, when k = 13, the average silhouette width is maximised, which means that, on average, observations are best matched to their own cluster and poorly matched to all other clusters. 

> Optimal number of clusters

From the elbow chart, I can identify an elbow shape when k = 13, and a relatively flat total within sum of squares from k = 13 - 17. Using the silhouette method, I observe that the maximum average silhouette width, and thus the maximum average distance between clusters, occurs when k = 13. Further, relatively high silhouette widths for k = 14 - 17 ratify my findings from the elbow chart that k = 13-17 is a plausible range for the optimal number of clusters under k-means clustering.

## Comparing k-means with different k

> Simplifying: focusing in only on clusters using k-means for k = 3, 4 and 5 to identify which is most plausible.

```{r fit_k-means_with_different_k}
#Fit k-means models

set.seed(1)
model_kmeans_3clusters<-eclust(userdata_sel, "kmeans", k = 3, nstart = 50, graph = FALSE)
model_kmeans_4clusters<-eclust(userdata_sel, "kmeans", k = 4, nstart = 50, graph = FALSE)
model_kmeans_5clusters<-eclust(userdata_sel, "kmeans", k = 5, nstart = 50, graph = FALSE)

# size of clusters
model_kmeans_3clusters$size
model_kmeans_4clusters$size
model_kmeans_5clusters$size

```

```{r PCA_visualization_with_different_k, fig.height=7, fig.width=15, fig.align = "centre"}
#PCA visualizations

#FOR K=3
kmeans_3_pca <- fviz_cluster(model_kmeans_3clusters, userdata_sel, palette = "Set2", main="K-Means Cluster Plot Across Two Principal Components, k = 3", x="Dimension 1 (10.9%)", y="Dimension 2 (9.6%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

kmeans_3_pca 

#FOR K=4
kmeans_4_pca <- fviz_cluster(model_kmeans_4clusters, userdata_sel, palette = "Set2", main="K-Means Cluster Plot Across Two Principal Components, k = 4", x="Dimension 1 (10.9%)", y="Dimension 2 (9.6%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

kmeans_4_pca 

#FOR K=5
kmeans_5_pca <- fviz_cluster(model_kmeans_5clusters, userdata_sel, palette = "Set2", main="K-Means Cluster Plot Across Two Principal Components, k = 5", x="Dimension 1 (10.9%)", y="Dimension 2 (9.6%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

kmeans_5_pca
```

```{r PCA_visualization_with_different_k:all, fig.height=10, fig.width=20, fig.align = "centre"}
kmeans_3_pca+labs(title= "K-Means Cluster Plot Across Two PCs",subtitle="k=3") + kmeans_4_pca+labs(title="",subtitle="k=4") + kmeans_5_pca+labs(title="",subtitle="k=5")

```

```{r centers_for_different_k, fig.width=15, fig.height = 5, message= FALSE, warning=FALSE}
#Plot centers

cluster_centers3<-data.frame(cluster=as.factor(c(1:3)),model_kmeans_3clusters$centers)
cluster_centers4<-data.frame(cluster=as.factor(c(1:4)),model_kmeans_4clusters$centers)
cluster_centers5<-data.frame(cluster=as.factor(c(1:5)),model_kmeans_5clusters$centers)

#transpose data frames
cluster_centers3_t<-cluster_centers3 %>% gather(variable,value,-cluster,factor_key = TRUE)
cluster_centers4_t<-cluster_centers4 %>% gather(variable,value,-cluster,factor_key = TRUE)
cluster_centers5_t<-cluster_centers5 %>% gather(variable,value,-cluster,factor_key = TRUE)

#FOR K=3

kmeans3_centers <- ggplot(cluster_centers3_t, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title="K-means Cluster Centers, k=3", x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

kmeans3_centers
```

```{r centers_for_different_3, fig.width=15, fig.height = 5, message= FALSE, warning=FALSE}
#FOR K=4

kmeans4_centers <- ggplot(cluster_centers4_t, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title="K-means Cluster Centers, k=4", x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

kmeans4_centers
```

```{r centers_for_different_5, fig.width=15, fig.height = 5, message= FALSE, warning=FALSE}
#FOR K=5

kmeans5_centers <- ggplot(cluster_centers5_t, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title="K-means Cluster Centers, k=5", x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

kmeans5_centers
```

```{r centers_for_different_all, fig.width=15, fig.height = 15, message= FALSE, warning=FALSE}
kmeans3_centers/ kmeans4_centers / kmeans5_centers


```

Based on the graphs above, k = 3 seems to be more plausible, since at this level clusters are less overlapped in PCA visualization, and the cluster centers are more clearly distinguished than for either k = 4 or 5. 

In all three cases, I observe that cluster 2 (in the k=3 case) is very well distinguished, with a relatively stable size (181, 180, 182) when I vary k from 3 to 5. From the k-means (k=3) center graph I observe that these are the people who enjoy viewing in the afternoon, with a strong preference for children's content and less preference for any other types of content. Furthermore, it seems that cluster 3 (in all examples) is relatively stable, broadly representing customers that tend to watch News and Weather shows. However, this cluster varies in terms of size as k increases from 3 to 5 (1603 vs 622 vs 813). 

# Comparing results of different clustering algorithms

## PAM

I now fit a PAM model for the k-value I chose for k-means (k=3).

```{r fit_PAM_model}

set.seed(1)

k=3

k3_pam <-eclust(userdata_sel, "pam", k = k, graph = FALSE)

#let's see the cluster sizes
k3_pam$clusinfo 

```

```{r PAM centers, fig.height=5, fig.width=15, fig.align="centre"}

userdata_sel_withClusters<-mutate(userdata_sel, cluster = as.factor(k3_pam$cluster))

center_locations <- userdata_sel_withClusters%>% group_by(cluster) %>% summarize_at(vars(total_Time:mean_percentage_viewed),mean)

#next I use gather to collect information together
xa2p<- gather(center_locations, key = "variable", value = "value",-cluster,factor_key = TRUE)

#next I use ggplot to visualize centers
pamcenters<-ggplot(xa2p, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title=paste0("PAM Cluster Centers, k=",k), x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

pamcenters
```

```{r PAM_Medoids, fig.height=5, fig.width=15, fig.align="centre"}

#First generate a new data frame with cluster medoids and cluster numbers
cluster_medoids<-data.frame(cluster=as.factor(c(1:k)),k3_pam$medoids)

#transpose this data frame
cluster_medoids_t<-cluster_medoids %>% gather(variable,value,-cluster,factor_key = TRUE)

#plot medoids
graphkmeans_3Pam<-ggplot(cluster_medoids_t, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title=paste0("PAM Medoids Cluster Centers, k=",k), x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

graphkmeans_3Pam

```
```{r PAM_PCA, fig.height=10, fig.width=10, fig.align="centre"}

pam_pca <- fviz_cluster(k3_pam, userdata_sel, palette = "Set2", main="PAM Cluster Plot Across Two Principal Components, k = 3", x="Dimension 1 (10.9%)", y="Dimension 2 (9.6%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

pam_pca

```

## H-Clustering

I now also use Hierarchical clustering with the same k (k=3) as above, comparing both 'average' and 'ward' methods.

```{r h-cluster}

set.seed(1)

res.dist <- dist(userdata_sel, method = "euclidean")

res.hc.avg <-  hcut(res.dist, hc_method = "average", k=3)
res.hc.wardD <-  hcut(res.dist, hc_method = "ward.D", k=3)

```

```{r 2methods_of_h-cluster, fig.width=12}

res.hc.avg$size
res.hc.wardD$size
plot(res.hc.avg,hang = -1, cex = 0.5)
plot(res.hc.wardD,hang = -1, cex = 0.5)

```

Each method resulted in completely different distances between clusters. The 'Average' method results in significantly smaller distances compared to distances from 'ward.D' method. Further, there is a significant difference in terms of cluster sizes. 

While the Average method resulted in one big cluster (3623) , and two small clusters consisting of only individual points, the 'ward.D' method produced more diversified clusters in terms of size (2605, 849, 171). It seems that one cluster may bear resemblance to a cluster from k=3 K-means clustering approach.

*I now plot the centers of H-clusters and compare the results with both K-Means and PAM*

```{r h-clustering_average_centers, fig.height=5, fig.width=15, fig.align="centre"}

userdata_sel_withClusters<-mutate(userdata_sel, cluster = as.factor(res.hc.avg$cluster))

center_locations <- userdata_sel_withClusters%>% group_by(cluster) %>% summarize_at(vars(total_Time:mean_percentage_viewed),mean)

xa2<- gather(center_locations, key = "variable", value = "value",-cluster,factor_key = TRUE)

#Next I use ggplot to visualize centers
hclust_avg_center<-ggplot(xa2, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title=paste0("Hierarchical (Average Method)  Cluster Centers, k=",k), x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

hclust_avg_center

```

```{r h-clustering_wardD_centers, fig.height=5, fig.width=15, fig.align="centre"}

userdata_sel_withClusters<-mutate(userdata_sel, cluster = as.factor(res.hc.wardD$cluster))

center_locations <- userdata_sel_withClusters%>% group_by(cluster) %>% summarize_at(vars(total_Time:mean_percentage_viewed),mean)

xa2<- gather(center_locations, key = "variable", value = "value",-cluster,factor_key = TRUE)

#Next I use ggplot to visualize centers
hclust_wardD_center<-ggplot(xa2, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title=paste0("Hierarchical (Ward Method) Cluster Centers, k=",k), x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

hclust_wardD_center

```

```{r h-clustering_PCA, fig.height=10, fig.width=15, fig.align="centre"}

#AVERAGE METHOD

hc_avg_pca <- fviz_cluster(res.hc.avg, userdata_sel, palette = "Set2", main="Hierarchical Cluster Plot (Average Method) Across Two Principal Components, k = 3", x="Dimension 1 (10.9%)", y="Dimension 2 (9.6%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

hc_avg_pca

#WARD METHOD

hc_wardD_pca <- fviz_cluster(res.hc.wardD, userdata_sel, palette = "Set2", main="Hierarchical Cluster Plot (Ward Method) Across Two Principal Components, k = 3", x="Dimension 1 (10.9%)", y="Dimension 2 (9.6%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

hc_wardD_pca

```

```{r compare3methods_PCA, fig.width = 25, fig.height=15}

(kmeans3_centers + pamcenters) / (hclust_avg_center + hclust_wardD_center)

```

```{r compare_PCA, fig.width = 25, fig.height=20}

(kmeans_3_pca + pam_pca) / (hc_avg_pca + hc_wardD_pca)

```

> I now draw some conclusions on the basis of the methods employed above

I can conclude that K-means clustering and Hierarchical Clustering with the Ward method perform better than both PAM and H-Clustering (Average) methods, with more distinguished cluster centers and less overlap between clusters in PCA visualizations. 

According to the visualization of cluster centers, these two methods both identified a cluster of BBC iPlayer viewers with a strong preference for children's content and afternoon viewing. Furthermore, by checking the cluster size, I notice that k-means and h-clustering with wardD have one cluster of similar size (181 in k-means vs 171 in h-clustering, Ward). Therefore, I can state with some certainty that I have found a stable and particularly well-distinguished cluster. 

Further, though with less certainty, I can also distinguish a cluster of consumers that tend to watch news and weather shows. Although this cluster does not stand out in the K-means method, it is pronounced in the cluster center plots of both the PAM (where it is represented by Cluster 1) and Hierarchical (Ward) methods (represented by Cluster 2).

# Subsample check

I now seek to verify that the clusters I have identified are not spurious by dividing the data into two equal parts. 

In order to achieve this, I use K-means clustering, fixing the number of clusters, in these two data sets separately. 

My criterion will be that, if I obtain similar looking clusters, my conclusions are relatively robust.

```{r out_of_sample_check}

#the following code chunk splits the data into two. Replace ... with your data frame that contains the data

set.seed(1234)
train_test_split <- initial_split(userdata_sel, prop = 0.5)
testing <- testing(train_test_split) #50% of the data is set aside for testing
training <- training(train_test_split) #50% of the data is set aside for training

#Fit k-means to each dataset and compare your results

train_kmeans_3clusters<-eclust(training, "kmeans", k = 3, nstart = 50, graph = FALSE)
test_kmeans_3clusters<-eclust(testing, "kmeans", k = 3, nstart = 50, graph = FALSE)

```

```{r out_of_sample_cluster_center_check, fig.width = 20, fig.height = 15}

cluster_centers3_train<-data.frame(cluster=as.factor(c(1:3)),train_kmeans_3clusters$centers)
cluster_centers3_test<-data.frame(cluster=as.factor(c(1:3)),test_kmeans_3clusters$centers)

cluster_centers3_train_df<-cluster_centers3_train %>% gather(variable,value,-cluster,factor_key = TRUE)
cluster_centers3_test_df<-cluster_centers3_test %>% gather(variable,value,-cluster,factor_key = TRUE)

kmeans3_centers_train <- ggplot(cluster_centers3_train_df, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title=paste0("K-Means Cluster Centers (Training Data), k=",k), x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

kmeans3_centers_test <- ggplot(cluster_centers3_test_df, aes(x = variable, y = value))+  
  
  #using a line plot
  geom_line(aes(color =cluster,group = cluster), linetype = "dashed",size=1)+
  
  #with connected points
  geom_point(size=1,shape=4)+geom_hline(yintercept=0)+theme(text = element_text(size=10),
        axis.text.x = element_text(angle=45, hjust=1),)+
  
  #and a relevant title and subtitle
  labs(subtitle = "", title=paste0("K-Means Cluster Centers (Testing Data), k=",k), x="Variable",y="Value",color="Cluster")+ 
  
  #and a relevant theme
  theme_fivethirtyeight() + theme(axis.title = element_text()) +
  
  #and ensuring the variables are named appropriately
  scale_x_discrete(labels=c("Total Time","Weekend","Afternoon","Day","Evening","Night","News","Entertainment","Comedy","Drama","Factual","Music","Sport","Weather","Religious Ethics","Children","Learning","Mean % Viewed"))

kmeans3_centers / kmeans3_centers_train / kmeans3_centers_test

```

```{r out_of_sample_PCA_check, fig.width = 25, fig.height=15}

train_pca <- fviz_cluster(train_kmeans_3clusters, training, palette = "Set2", main="K-Means Cluster Plot (Training Data) Across Two PCs, k = 3", x="Dimension 1 (11.2%)", y="Dimension 2 (9.3%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())

test_pca <- fviz_cluster(test_kmeans_3clusters, testing, palette = "Set2", main="K-Means Cluster Plot (Testing Data) Across Two PCs, k = 3", x="Dimension 1 (10.8%)", y="Dimension 2 (9.9%)", legend.title="Cluster")+theme_fivethirtyeight() + theme(axis.title = element_text())


kmeans_3_pca + train_pca + test_pca

```

> Robustness Checks

Based on the graphs above, I are more confident in my results regarding one specific cluster (children's content viewers and afternoon viewing habit). 

Since k-means clustering with k = 3 performs relatively consistently in terms of both cluster centers and PCA across the whole data set, the train set and the test set, my clusters seem robust, and thus that the clusters identified are substantive and not simply due to chance. 

# Conclusions

> The Clusters which are likely to be substantive user profiles

I can confidently conclude that there is one outstanding cluster of users of the BBC's iPlayer platform who widely consume children's content and watch shows predominantly in the afternoon.

> Evaluation of optimal k

I believe k = 3 is the right choice, given the simplicity constraint of k=3-5, since the cluster centers are most distinguished from one another across the observed variables and clusters have the least overlap when evaluated in terms of principal components. 

my model's consistent out-of-sample performance also supports this decision. However, as shown in the elbow chart and silhouette analysis, there is likely to be be around 13 underlying clusters in my data, however this number of clusters may not be particularly insightful, since there is likely to be substantial overlap, meaning that interpretibility is low.  

> Assumptions these results are sensitive to, and how the robustness of results to differing assumptions could be evaluated

I assume that my analysis is sensitive to outliers (which is reflected by differing results in my PAM analysis compared to the K-means approach), choice of variables (for example, I could generate different measures for engagement besides average percentage completion, which may encourage formation of differing clusters), as well as to sample sizes. In order to check the robustness of my analysis, I would need to gather bigger sample over longer time period, ensuring that it is randomly selected and representative of the population at large. Perhaps with more data I could be more confident in having identified the second cluster of users who characteristically watch news and weather shows, though at present this remains a potentially spurious cluster.

> Applications of this cluster identification

**Content Recommendations Notifications to Boost Engagement**
For example, if a viewer mainly watches Children’s shows, then the BBC iPlayer app should send them notifications of recommended Children’s and Learning shows during the afternoon, since this is the time when this “Family” viewer is most likely to watch. Similarly, if a viewer mainly watches daytime News and Weather shows, notifications should be sent in the morning and recommend Sports, cross-selling other genres that the “Daytime Viewer” profile has a tendency to consume. 

**Targeted Advertisement to Boost Advertising Revenues**
At present BBC iPlayer does not allow third party advertisements, however, if it did, then these distinct viewer profiles would prove invaluable for targeting. For example, if a viewer mostly watches news during the day, I can expect that they are either retired or unemployed and target them with services such as holidays, loans and insurance. Alternatively, viewers who watch dramas in the evening can be targeted with products such as alcohol, fast food, cosmetics and cars. 

# **II/II. How Can We Recommend Them Suitable Films?**

## Loading the Data

```{r loading_data}

#I load the following two datasets - movies and their corresponding ratings
movie_data <- fread(here::here('data','movies.csv'),stringsAsFactors=FALSE)

rating_data <- fread(input = here::here('data','ratings.csv'), select = c(1:3), nrows = 1e6)

#I use the following genre list for my data
list_genre <- c("Action", "Adventure", "Animation", "Children", 
                "Comedy", "Crime","Documentary", "Drama", "Fantasy",
                "Film-Noir", "Horror", "Musical", "Mystery","Romance",
                "Sci-Fi", "Thriller", "War", "Western")

```

## Cleaning the Data

### Cleaning Movies Data

```{r cleaning_movies_data, results='hide',message=FALSE,warning=FALSE}

#I clean up those movies that appear more than once in the movie_data dataframe

#First, I see which movies appear more than once and save them as a vector

repeatMovies <- movie_data %>% 
  group_by(title) %>% 
  
  #I count appearance of each movie
  summarise(n = n()) %>% 
  
  #I filter for movies that appear more than once
  filter(n > 1) %>% 
  
  #I get the titles of those movies that appear more than once as a vector
  pull(title)

#I view the duplicated titles
repeatMovies

#I now initialize the variable that stores the rows I have to remove later (the duplicates)
removeRows <- integer()

#For each movie that is duplicated, I run the following code...

for(i in repeatMovies){
  
  ### REMOVE DUPLICATES IN MOVIES DATA ###
  
  #I get the indices of the rows where the current movie (with title i) is stored 
  #(this will be more than 1 row, since the movie is duplicated!)
  repeatMovieLoc <- which(movie_data$title == i)
  
  #I collapse the genres assigned to the duplicated movies, separated by |
  #With this line of code, I paste them both together as "Action|Drama|Drama"
  tempGenre <- paste(movie_data$genres[repeatMovieLoc], collapse="|")
  
  #I now split that string up again, and take only the unique values
  tempGenre <- paste(unique(unlist(strsplit(tempGenre, split = "\\|")[[1]])), collapse = "|")
  
  #In this line, I bring the new genre string to the first appearance of the movie in the dataframe
  movie_data$genres[repeatMovieLoc[1]] <- tempGenre
  
  #I then add the duplicate entry (row 6271) to the list of rows I want to remove later
  removeRows <- c(removeRows, repeatMovieLoc[-1])
  
  ### REMOVE DUPLICATES IN RATINGS DATA ###

  #I now search for all the entries in the rating_data dataframe that refer to duplicate movies in movie_data
  repeatMovieIdLoc <- which(rating_data$movieId %in% movie_data$movieId[removeRows])
  
  #With this information, I change the movieId to the movieId that remains in my movie_data dataframe,
  rating_data$movieId[repeatMovieIdLoc] <- movie_data$movieId[repeatMovieLoc[1]]
}

#Finally, I remove the duplicate rows in the movie_data dataframe
movie_data <- movie_data[-removeRows,]

```

### Cleaning Ratings Data

```{r cleaning_ratings_data, results='hide',message=FALSE,warning=FALSE}

#First, I see which users rated a movie more than once and save them as a vector

repeatRatings <- rating_data %>% 
  group_by(movieId,userId) %>% 
  
  #I count appearance of each movie
  summarise(n = n()) %>% 
  
  #I filter for movies that appear more than once
  filter(n > 1) %>% 
  
#I pull the duplicated userId movieId combinations
pull(userId,movieId)

#I view the duplicated userId movieId combinations
repeatMovies

#Since I have identified duplicates where the same user has rated a movie multiple times, I only take the best rating

#Here, I group by userId and movieId, and only take the highest (maximum) rating

#This means I end up with a dataframe where there is (at most) 1 user rating for a movie
#This constraint is necessary to build up a proper user-movie-interaction-matrix

rating_data <- rating_data %>% 
  group_by(userId, movieId) %>% 
  summarise(rating = max(rating)) %>% 
  ungroup()

#Further, I identify movies not rated by any user, which I are safe to ignore for now, since they shouldn't affect my recommendations
length(unique(rating_data$movieId))
length(unique(movie_data$movieId))
setdiff(unique(movie_data$movieId), unique(rating_data$movieId)) 

```

### Checking the Data is Clean

```{r performing_data_checks, results='hide',message=FALSE,warning=FALSE}

#movie_data
skim(movie_data)
summary(movie_data)    
head(movie_data)

#rating_data
skim(movie_data)
summary(rating_data)   
head(rating_data)

#I ensure there are no duplicate rows in either dataframe, meaning my cleaning has been successful

dupes_movie<-movie_data%>%get_dupes(movieId,title)
dupes_movie

dupes_rating<-rating_data%>%get_dupes(userId,movieId)
dupes_rating

```

```{r cross_matrix_of_genres, results='hide',message=FALSE,warning=FALSE}

searchMatrix <- movie_data %>% 
  
  #I split the genres assigned to movies into multiple rows
  separate_rows(genres, sep = "\\|") %>% 
  mutate(values = 1) %>% 
  
  #I then pivot the dataframe so that each genre is assigned its own column
  pivot_wider(names_from = genres, values_from = values) %>% 
  replace(is.na(.), 0)

#Though I find that there are 22 movies with no genres listed, this is not problematic for the recommendation model, since it is purely collaborative, rather than content-based
searchMatrix %>% 
  filter(`(no genres listed)`==1) %>% 
  length()

```

I find, as intended, that each row of the movie_data represents a unique movie, and each row of the rating_data represents a unique user-movie rating combination, representing the maximum rating that each user gave for any given movie. 

## Building the Rating Matrix (User-Movie-Interactions Matrix)

```{r rating_matrix, results='hide',message=FALSE,warning=FALSE}

#A ratings matrix consists of userId's as rows and movieId's as columns
ratingMatrix <- rating_data %>% 
  arrange(movieId) %>% 
  
  #I allocate each movie to its own column
  pivot_wider(names_from = movieId, values_from = rating) %>% 
  arrange(userId) %>% 
  
  #I drop userId
  select(-userId)

#I convert the dataframe created above into a matrix
ratingMatrix <- as.matrix(ratingMatrix)

#I order the rows and columns so that those with the fewest NAs are furthest to the top left, which is crucial for selecting the most popular movies and most frequent users
ratingMatrix <- ratingMatrix[order(rowSums(is.na(ratingMatrix))),order(colSums(is.na(ratingMatrix)))]

#I perform a brief check to ensure that I still have same set of movies
setdiff(movie_data$movieId, as.integer(colnames(ratingMatrix)))

#I find that 18 movies present in the original movie_data are not present in the new ratingMatrix
#However, this data loss is unlikely to affect my analysis, so it is safe to ignore 

#I now convert the rating matrix into a recommenderlab sparse matrix
ratingMatrix <- as(ratingMatrix, "realRatingMatrix")
ratingMatrix

```

## **STEP 1 - EXPLORATORY ANALYSIS**

## Preparing the Data

### Ratings Counts 
```{r evaluating_the_data_for_exploratory_analysis, results='hide',message=FALSE,warning=FALSE}

#I create a count of movie ratings
rating_data %>% 
  group_by(rating) %>% 
  summarise(n = n())

#I create a table with number of ratings per movie
movie_rating_count <- rating_data %>% 
  group_by(movieId) %>% 
  summarise(ratings = n()) %>% 
  left_join(movie_data, by = "movieId") %>% 
  select(movieId, title, ratings) %>% 
  arrange(desc(ratings))

#I preview the table with the count of ratings per movie to ensure it has been defined correctly
head(movie_rating_count)

#I create a table with number of ratings per user
user_rating_count <- rating_data %>% 
  group_by(userId) %>% 
  summarise(ratings = n()) %>% 
  arrange(desc(ratings))

#I preview the table with the count of ratings per movie to ensure it has been defined correctly
head(user_rating_count)

```

### Selecting only Top 100 Most Popular Movies and Top 100 Most Frequent Users
```{r applying_popularity_and_frequency_criteria, fig.height=10, fig.width=10, results='hide',message=FALSE,warning=FALSE}

#I only take the 100 most popular movies and 100 most popular users

top100_movies_users_ratings <- ratingMatrix[1:100,1:100]

#I now have only the top 100 most popular movies and top 100 most frequent users in my matrix, containing 6223 ratings
top100_movies_users_ratings

```

```{r plotting_top100movies_top100users, results='hide',message=FALSE,warning=FALSE}

#I build a plot which visualises this "Top100" user-movie-interaction-matrix (ratingMatrix)
image(top100_movies_users_ratings, axes = FALSE, main = "Heatmap of the 100 Most Popular Movies and 100 Most Frequent Users")

#Since this is relatively difficult to understand visually, I showcase just top top 25 most popular movies and top 25 most frequent users

image(top100_movies_users_ratings[1:25,1:25], axes = FALSE, main = "Heatmap of the 25 Most Popular Movies and 25 Most Frequent Users")

```

The heatmap demonstrating ratings of the top 25 most frequent users and top 25 most popular movies is predominantly very dark, which means that the top users, who have rated a lot of movies, really like the movies that are rated most often. 

## How similar the 100 most popular movies are to eachother
```{r similarity_100_popular_movies, fig.height=10, fig.width=10, results='hide',message=FALSE,warning=FALSE}


#I produce a matrix which calculates how similar movies are to one another
movie_similarity <- similarity(ratingMatrix[, 1:100],
                               method = "cosine",
                               which = "items")

#I also add diag(100), since the similarity of a movie with itself is 1
movie_similarity <- as.matrix(movie_similarity) + diag(100)

image(movie_similarity, main = "Similarity of the 100 Most Popular Movies")

```

## How similar the 100 most frequent users are to eachother
```{r similarity_100_frequent_users, fig.height=10, fig.width=10, results='hide',message=FALSE,warning=FALSE}

#I produce a matrix which calculates how similar users are to one another
user_similarity <- similarity(ratingMatrix[1:100, ],
                              method = "cosine",
                              which = "users")

#I also add diag(100), since the similarity of a user with themselves is 1
user_similarity <- as.matrix(user_similarity) + diag(100)

image(user_similarity, main = "Similarity of the 100 Most Frequent Users")

```

## Build a Histogram to Show the Frequency of Ratings of All Movies
```{r histogram_frequency_movie_ratings, fig.height=5, fig.width=10, results='hide',message=FALSE,warning=FALSE}

#I evaluate the count of number of ratings received by movies
movie_rating_count<-rating_data %>% 
  group_by(movieId) %>% 
  count()

#I build a histogram showing the frequency of ratings of all movies
movie_rating_count %>% 
  ggplot(aes(n)) + 
  geom_histogram(binwidth=5) +
  labs(title="Most Commonly, Movies Have 5 Ratings or Less",subtitle = "Frequency of Movie Ratings Received",x="Number of Ratings per Movie",y="Count") + 
  theme_bw()+
  theme(axis.title = element_text())

```

## Build a Histogram to Show the Frequency of Ratings of All Users
```{r histogram_frequency_user_ratings, fig.height=5, fig.width=10, results='hide',message=FALSE,warning=FALSE}

#I evaluate the count of number of ratings given by Users
user_rating_count<-rating_data %>% 
  group_by(userId) %>% 
  count()

#I build a histogram showing the frequency of ratings of all movies
user_rating_count %>% 
  ggplot(aes(n)) + 
  geom_histogram(binwidth=10) +
  labs(title="Users Most Commonly Rate between 10 and 20 Movies",subtitle = "Frequency of User Ratings Given",x="Number of Ratings per User",y="Count") + 
  theme_bw()+
  theme(axis.title = element_text())

```

## **STEP 2 - SELECTING THE MOST COMMON USERS AND MOVIES**

## Selecting movies with more than 'm' ratings and users who have given more than 'n' ratings, where m <- c(10, 20, 50, 100, 200); n <- m

```{r m most common movies and n most common users, results='hide',message=FALSE,warning=FALSE}

#Since the rows (users) and columns (movies) of my ratingMatrix are already ranked in decreasing order of frequency/popularity, I can just slice the matrix

#movies rated more than 10 times and users who have rated at least 10 movies
top10_rate <- ratingMatrix[rowCounts(ratingMatrix) >= 10,colCounts(ratingMatrix) >= 10] 
top10_rate <- top10_rate[rowCounts(top10_rate) > 5,] 

#movies rated more than 20 times and users who have rated at least 20 movies
top20_rate <- ratingMatrix[rowCounts(ratingMatrix) >= 20,colCounts(ratingMatrix) >= 20] 
top20_rate <- top20_rate[rowCounts(top20_rate) > 5,] 

#movies rated more than 50 times and users who have rated at least 50 movies
top50_rate <- ratingMatrix[rowCounts(ratingMatrix) >= 50,colCounts(ratingMatrix) >= 50] 
top50_rate <- top50_rate[rowCounts(top50_rate) > 5,] 

#movies rated more than 100 times and users who have rated at least 100 movies
top100_rate <- ratingMatrix[rowCounts(ratingMatrix) >= 100,colCounts(ratingMatrix) >= 100] 
top100_rate <- top100_rate[rowCounts(top100_rate) > 5,] 

#movies rated more than 200 times and users who have rated at least 200 movies
top200_rate <- ratingMatrix[rowCounts(ratingMatrix) >= 200,colCounts(ratingMatrix) >= 200]
top200_rate <- top200_rate[rowCounts(top200_rate) > 5,] 

```

## **STEP 3 - BUILDING RECOMMENDATION SYSTEMS**

## Splitting each subset into test and training data

```{r splitting into training and testing data, results='hide',message=FALSE,warning=FALSE}

#I set the seed to ensure reproducibility
set.seed(1)

#I intend to train my models on 80% of the data and test it on the remaining 20%
#I split the data into test and training data

top10_split <- evaluationScheme(top10_rate, method="split", train=0.8, given=-5)
top20_split <- evaluationScheme(top20_rate, method="split", train=0.8, given=-5)
top50_split <- evaluationScheme(top50_rate, method="split", train=0.8, given=-5)
top100_split <- evaluationScheme(top100_rate, method="split", train=0.8, given=-5)
top200_split <- evaluationScheme(top200_rate, method="split", train=0.8, given=-5)

```

## Building three separate recommendations systems (Item  Based CF, User Based CF and a Model Based CF using Matrix Factorisation) for each of the values of 'n' and 'm' (5 versions for each type of RS)

```{r item_based_CF, results='hide',message=FALSE,warning=FALSE}

#TOP10
top10_IBCF <- Recommender(getData(top10_split, "train"), method = "IBCF",param=list(k=25))

#TOP20
top20_IBCF <- Recommender(getData(top20_split, "train"), method = "IBCF",param=list(k=25))

#TOP50
top50_IBCF <- Recommender(getData(top50_split, "train"), method = "IBCF",param=list(k=25))

#TOP100
top100_IBCF <- Recommender(getData(top100_split, "train"), method = "IBCF",param=list(k=25))

#TOP200
top200_IBCF <- Recommender(getData(top200_split, "train"), method = "IBCF",param=list(k=25))

```

```{r user_based_CF, results='hide',message=FALSE,warning=FALSE}

#TOP10
top10_UBCF <- Recommender(getData(top10_split, "train"), method = "UBCF",param=list(nn=25))

#TOP20
top20_UBCF <- Recommender(getData(top20_split, "train"), method = "UBCF",param=list(nn=25))

#TOP50
top50_UBCF <- Recommender(getData(top50_split, "train"), method = "UBCF",param=list(nn=25))

#TOP100
top100_UBCF <- Recommender(getData(top100_split, "train"), method = "UBCF",param=list(nn=25))

#TOP200
top200_UBCF <- Recommender(getData(top200_split, "train"), method = "UBCF",param=list(nn=25))

```

```{r model_based_CF_using_MF, results='hide',message=FALSE,warning=FALSE}

#TOP10
top10_LIBMF <- Recommender(getData(top10_split, "train"), method = "LIBMF",param = list(dim = 10))

#TOP20
top20_LIBMF <- Recommender(getData(top20_split, "train"), method = "LIBMF",param = list(dim = 10))

#TOP50
top50_LIBMF <- Recommender(getData(top50_split, "train"), method = "LIBMF",param = list(dim = 10))

#TOP100
top100_LIBMF <- Recommender(getData(top100_split, "train"), method = "LIBMF",param = list(dim = 10))

#TOP200
top200_LIBMF <- Recommender(getData(top200_split, "train"), method = "LIBMF",param = list(dim = 10))

```

## **STEP 4 - COMPUTING RMSE OF EACH MODEL AND COMBINATION OF [M x N]**

## Assessing the  performance of the above models for different number of 'items' and 'users'. Remember CF methods are most appropriate for high volume items (often watched movies) and frequent users. 

```{r RMSE_item_based_CF, results='hide',message=FALSE,warning=FALSE}

set.seed(1)

#TOP10

#I compute predicted ratings by giving the model the known part of the test data 
#(i.e. the data of the users for all but 5 movies for each user)
top10_IBCF_predict <- predict(top10_IBCF, getData(top10_split, "known"), type="ratings")

#Finally, I can calculate RMSE between the predictions and the unknown part of the test data 
#(i.e. for the 5 movies that were held out)
top10_IBCF_RMSE <- calcPredictionAccuracy(top10_IBCF_predict, getData(top10_split, "unknown"))[1]

#TOP20
top20_IBCF_predict <- predict(top20_IBCF, getData(top20_split, "known"), type="ratings")
top20_IBCF_RMSE <- calcPredictionAccuracy(top20_IBCF_predict, getData(top20_split, "unknown"))[1]

#TOP50
top50_IBCF_predict <- predict(top50_IBCF, getData(top50_split, "known"), type="ratings")
top50_IBCF_RMSE <- calcPredictionAccuracy(top50_IBCF_predict, getData(top50_split, "unknown"))[1]

#TOP100
top100_IBCF_predict <- predict(top100_IBCF, getData(top100_split, "known"), type="ratings")
top100_IBCF_RMSE <- calcPredictionAccuracy(top100_IBCF_predict, getData(top100_split, "unknown"))[1]

#TOP200
top200_IBCF_predict <- predict(top200_IBCF, getData(top200_split, "known"), type="ratings")
top200_IBCF_RMSE <- calcPredictionAccuracy(top200_IBCF_predict, getData(top200_split, "unknown"))[1]

```

```{r RMSE_user_based_CF, results='hide',message=FALSE,warning=FALSE}

set.seed(1)

#TOP10
top10_UBCF_predict <- predict(top10_UBCF, getData(top10_split, "known"), type="ratings")
top10_UBCF_RMSE <- calcPredictionAccuracy(top10_UBCF_predict, getData(top10_split, "unknown"))[1]

#TOP20
top20_UBCF_predict <- predict(top20_UBCF, getData(top20_split, "known"), type="ratings")
top20_UBCF_RMSE <- calcPredictionAccuracy(top20_UBCF_predict, getData(top20_split, "unknown"))[1]

#TOP50
top50_UBCF_predict <- predict(top50_UBCF, getData(top50_split, "known"), type="ratings")
top50_UBCF_RMSE <- calcPredictionAccuracy(top50_UBCF_predict, getData(top50_split, "unknown"))[1]

#TOP100
top100_UBCF_predict <- predict(top100_UBCF, getData(top100_split, "known"), type="ratings")
top100_UBCF_RMSE <- calcPredictionAccuracy(top100_UBCF_predict, getData(top100_split, "unknown"))[1]

#TOP200
top200_UBCF_predict <- predict(top200_UBCF, getData(top200_split, "known"), type="ratings")
top200_UBCF_RMSE <- calcPredictionAccuracy(top200_UBCF_predict, getData(top200_split, "unknown"))[1]

```

```{r RMSE_model_based_CF_using_MF, results='hide',message=FALSE,warning=FALSE}

set.seed(1)

#TOP10
top10_LIBMF_predict <- predict(top10_LIBMF, getData(top10_split, "known"), type="ratings")
top10_LIBMF_RMSE <- calcPredictionAccuracy(top10_LIBMF_predict, getData(top10_split, "unknown"))[1]

#TOP20
top20_LIBMF_predict <- predict(top20_LIBMF, getData(top20_split, "known"), type="ratings")
top20_LIBMF_RMSE <- calcPredictionAccuracy(top20_LIBMF_predict, getData(top20_split, "unknown"))[1]

#TOP50
top50_LIBMF_predict <- predict(top50_LIBMF, getData(top50_split, "known"), type="ratings")
top50_LIBMF_RMSE <- calcPredictionAccuracy(top50_LIBMF_predict, getData(top50_split, "unknown"))[1]

#TOP100
top100_LIBMF_predict <- predict(top100_LIBMF, getData(top100_split, "known"), type="ratings")
top100_LIBMF_RMSE <- calcPredictionAccuracy(top100_LIBMF_predict, getData(top100_split, "unknown"))[1]

#TOP200
top200_LIBMF_predict <- predict(top200_LIBMF, getData(top200_split, "known"), type="ratings")
top200_LIBMF_RMSE <- calcPredictionAccuracy(top200_LIBMF_predict, getData(top200_split, "unknown"))[1]

```

## Summary Data Frame of All the RMSEs

```{r RMSE_dataframe, results='hide',message=FALSE,warning=FALSE}

RMSE_data <- data.frame("number_ratings"=c(10,20,50,100,200),"IBCF"=c(top10_IBCF_RMSE,top20_IBCF_RMSE,top50_IBCF_RMSE,top100_IBCF_RMSE,top200_IBCF_RMSE),"UBCF"=c(top10_UBCF_RMSE,top20_UBCF_RMSE,top50_UBCF_RMSE,top100_UBCF_RMSE,top200_UBCF_RMSE),"LIBMF"=c(top10_LIBMF_RMSE,top20_LIBMF_RMSE,top50_LIBMF_RMSE,top100_LIBMF_RMSE,top200_LIBMF_RMSE))

RMSE_dataround <- round(RMSE_data,3)

```

```{r RMSE_kable_table, results='hide',message=FALSE,warning=FALSE}

RMSE_table <- kable(RMSE_dataround, col.names=c("Number of Ratings Per User and Movie","IBCF","UBCF","LIBMF")) %>% 
  kable_material_dark() %>% 
  add_header_above(c(" " = 1,"RMSE"=3))

RMSE_table

```

## **STEP 5 - REPORTING PLOTS SHOWING HOW RMSE CHANGES GIVEN THE MODEL AND VALUES OF 'N' AND 'M'**

## Your X-axis should be values of n,m and your y-axis should be RMSE

```{r RMSE_plot_3models_5samples, fig.height=10, fig.width=10, results='hide',message=FALSE,warning=FALSE}

RMSE_data_longer<- pivot_longer(RMSE_data,cols=2:4,names_to="recommendationSystem",values_to="RMSE")

ggplot(RMSE_data_longer, aes(x=number_ratings,y=RMSE,colour=recommendationSystem))+
  geom_line(size=0.5)+
  theme_solarized_2(light = FALSE) + 
  scale_colour_solarized("blue")+
  labs(title="Recommendation Performance Improves When Trained on More Common Users and Movies", subtitle="RMSE for 3 Model Specifications, Trained on 5 Data Subsets",x="Minimum Number of Reviews Given by Users and Received by Movies", y="Root Mean Square Error (RMSE)",col="Recommendation System")+
  theme(strip.text=element_text(colour="white"))+
  theme(axis.text=element_text(colour="white")) +
  theme(axis.title.y=element_text(colour="white"))+
  theme(axis.title.x=element_text(colour="white"))+
  theme(plot.title=element_text(colour="white"))+
  theme(legend.text=element_text(colour="white"))+
  theme(legend.title = element_text(colour="white"))+
  theme(plot.subtitle=element_text(colour="white"))+
  theme(legend.position="top")+
  scale_y_continuous(breaks=seq(0.70,1.55,0.05),limits=c(0.70,1.55))+
  scale_x_continuous(breaks=c(10,20,50,100,200),limits=c(0,200))+
  geom_point()
  
```
On the basis of the RMSE's above, my recommended recommendation system (which minimises RMSE) is: LIBMF, trained on a subset of the data including only movies that have been rated at least 50 times, and users that have given at least 50 ratings. 
