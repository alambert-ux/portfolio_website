---
date: "2017-10-31T21:28:43-05:00"
description: "How Has Usage of Hired Bikes in London Deviated from Expectations since the COVID-19 Pandemic?"
draft: false
image: pic12.jpg
keywords: ""
slug: odum
title: Odum

---

# The Problem

Santander Bikes (or "Boris Bikes", in recognition of the then-Mayor of London Boris Johnson), are widely used across the City of London by tens of thousands of people every day. Understanding how many bikes are likely to be in use on a given day of the week, and a given month of the year is crucial for making decisions around how many bikes to provide, how often they need to be serviced, and make revenue and profitability forecasts crucial for informing future investment in "green" technologies and services in the City of London. 

# The Data
 
I employ a key dataset of from Transport for London, to visualise how bike useage varies across days, weeks and months, and how this deviates from long-term expectations. The data is pulled live from TfL, and runs from 2015 to the present day. 

# The Solution

### How London Bike Hires Vary Over Weekdays, Months and Years, Versus Long-Term Expectations

**First, the required packages are loaded...**
```{r load-libraries, results=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(infer)
library(patchwork)
library(kableExtra)
library(scales) 
```

**Next, the dataset itself is imported and cleaned...**
```{r, get_tfl_data, cache=TRUE, results=FALSE, message=FALSE, warning=FALSE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))
```

## Monthly Deviations in Bike Usage

**We now create a facet grid that plots bikes hired by month and year...**
```{r monthly_changes, results=FALSE, message=FALSE, warning=FALSE}

bike_mon <- bike %>%
  filter(year >= 2015) %>%
  group_by(year, month)%>%
  summarise(mean_hired.act=mean(bikes_hired))%>% # average number of bikes hired each day for each month in each year
  group_by(month) %>%
  mutate(mean_hired.exp=mean(mean_hired.act)) # average of *the average number of bikes hired each day in each month*, across all years from 2015-2020 i.e. the value for month X is obtained by averaging the average number of bikes hired each day in month X from 2015-2020. 

#we publish the underlying data set as a clean table
  kbl(bike_mon, col.names=c("Year","Month","Mean Number of Bikes Hired Daily (Actual)", "Mean Number of Bikes Hired Daily (Expected)")) %>%
  kable_styling()

```

```{r monthly_changes_plot, fig.height=5, fig.width=10, fig.align="centre"}

monthly_plot <- ggplot(bike_mon,aes(x=month,group=1))+   
  geom_line(aes(y=mean_hired.exp),color="blue",size=0.7) + 
  geom_line(aes(y=mean_hired.act),color="black",size=0.3)+
  
 geom_ribbon(aes(x=month,ymin=mean_hired.exp,ymax=pmax(mean_hired.act,mean_hired.exp)),fill="green",alpha=0.2)+ 
geom_ribbon(aes(x=month,ymin=pmin(mean_hired.act,mean_hired.exp),ymax=mean_hired.exp),fill="red",alpha=0.2) + # 2 ribbons for each of the color(above and below the blue constant line)
  
facet_wrap(~year)+
    theme_minimal() +
  
  #controlling size of axis titles and text 
   theme(legend.position = "none",
         axis.title.y = element_text(size=rel(1)),
         plot.title = element_text(size=rel(1.4),face="bold"),
         axis.text.x = element_text(size=rel(0.8),angle=0))+
  
  # adding labels and source annotation
  labs(y = "Bike rentals",
       x = NULL,
       title = "Monthly changes in TfL bike rentals",
       subtitle = "Change from monthly average shown in blue 
and calculated between 2015-2019", caption="Source: TfL, London Data Store")

monthly_plot


```

### An Interpretation

Distribution of Bikes hired in the month of May and June in 2020 varies significantly from previous years. The standard deviation has increased as the curve looks flattened out. As a result the peak is not occurring at the usual value of around 40k bikes hired. This can be attributed to Lockdown measures put in place in response to the COVID-19 outbreak.

This plot shows clearly how February-May 2020 marks a stark contrast to all previous years, due to Lockdown measures. Interestingly, there is also a substantial "rebound" from May to July as bike usage increases well over the long-term average expected level. It is interesting to see the difference between 2018 and 2019, too: 2018 experienced "the beast from the East", a cold front that caused snow throughout February and March, which evidently depressed bike usage well below the long-term average. Contrastingly, 2019 experienced a moderate Spring. Less consistent is the fact that bike usage falls below the long-term expectation across Summer 2019, which included some of the hottest days on UK record. This indicates that both extreme heat and cold inhibit bike usage in London, a relationship which warrants further investigation

## Weekly Deviations in Bike Usage

The plot below looks at percentage changes from the expected level of weekly rentals. The two grey shaded rectangles correspond to the second (weeks 14-26) and fourth (weeks 40-52) quarters.

```{r weekly_change_percentage, results=FALSE, message=FALSE, warning=FALSE}

bike_week <- bike %>%
  filter(year >=2015) %>%
  group_by(year,week)%>% # average number of bikes hired each day for each week in each year
  summarise(mean_hired.act=mean(bikes_hired))%>%
  group_by(week) %>%
  mutate(mean_hired.exp=mean(mean_hired.act)) # average of *the average number of bikes hired each day in each week*, across all years from 2015-2020 i.e. the value for week X is obtained by averaging the average number of bikes hired each day in week X from 2015-2020. 

# adding percentage change in weekly average of bikes hired across different years
bike_week$mean_hired.exc = ((bike_week$mean_hired.act-bike_week$mean_hired.exp)/bike_week$mean_hired.exp)

#we publish the underlying data set as a clean table
  kbl(bike_week, col.names=c("Year","Week","Mean Number of Bikes Hired Daily (Actual)", "Mean Number of Bikes Hired Daily (Expected)", "Deviation of Actual Bikes Hired from Expected Bikes Hired (Proportion)")) %>%
  kable_styling()

```

``` {r weekly_change_percentage_plot, fig.height=5, fig.width=10, fig.align="centre"}

weekly_plot <- bike_week %>%
  ggplot(aes(x=week,group=1))+ 
  geom_line(aes(y=mean_hired.exc),size=0.3) + # add line for change rate
  
  # add grey tiles for 2 quarters
  geom_tile(aes(x = 19.5, y = 0, width = 13, height = 1.2), fill = 'grey', alpha = 0.01) +
  geom_tile(aes(x = 46, y = 0, width = 13, height = 1.2), fill = 'grey', alpha = 0.01) +  
  
  # if change rate > 0 , fill with green
  geom_ribbon(aes(x=week,ymin=0,ymax=pmax(bike_week$mean_hired.exc,0)),fill="green",alpha=0.3)+
  # if change rate < 0 , fill with red
  geom_ribbon(aes(x=week,ymin=pmin(bike_week$mean_hired.exc,0),ymax=0),fill="red",alpha=0.3) +
  
  facet_wrap(~year) +
  scale_x_continuous(limits = c(0, 53),breaks=c(13,26,39,53)) + # specify breaks for x
  scale_y_continuous(labels = label_percent(),limits = c(-0.6,0.6),breaks=c(-0.6,-0.3,0,0.3,0.6)) +
  theme_minimal() +
  
  # adjust title text size
  theme(legend.position = "none",
        axis.title.y = element_text(size=rel(1)),
        plot.title = element_text(size=rel(1.4),face="bold"),
        axis.text.x = element_text(size=rel(0.8),angle=0,face="bold")) +
  # add labs
  labs(title = 'Weekly change in TfL bike rentals',
       y = '',
       subtitle = '% change from weekly averages
calculated between 2015-2019', caption="Source: TfL, London Data Store") +
  
  # if change rate > 0 , rug = green
  geom_rug(data = subset(bike_week,mean_hired.exc > 0), color = 'green', sides="b", size = 0.3) +
  # if change rate < 0 , rug = red
  geom_rug(data = subset(bike_week, mean_hired.exc<0), color = 'red', sides="b", size = 0.3) 
 
weekly_plot

```

### An Interpretation

Here, again, the impact of COVID-19 and the Spring 2020 Lockdown is evident. While in both 2017 and 2019 Week 13 was the highest peak in percentage change in bike usage across the whole year, in 2020 this same week was the trough, as Lockdown measures were imposed on the city. 

**A Note on Long-Term Averages**

Expected rentals (weekly or monthly) are generated by averaging weekly or monthly averages of daily bike usage across the years surveyed. In this context, we have 6 averages for each week/month, across the period 2015-2020, which we average to calculate expectations. Given that each of these weekly/monthly averages is not substantially different across years, we have no major outliers in our data, which means that using the median to calculate expected rentals is not particularly beneficial. 

In fact, we can expect that the average weekly/monthly rentals are normally distributed for a given week/month across years. i.e. if we plotted the weekly/monthly average daily bike usage for a given week/month for each of N years, we would find that the distribution of averages for each week/month would be normally distributed across all N years in our sample. 

As such, the mean is the optimal measure, since the expected rentals is a function (cross-year average) of the weekly/monthly average of daily bike rentals, which we are (justifiably) assuming is normally distributed for each week/month across the years surveyed. 

## Occam's Razor

This brief analysis has demonstrated the dramatic effect of COVID-19 government-imposed measures on usage of communally accessible bikes in the City of London. There is significant scope for further analyses, specifically converting these insights into revenue estimates and forecasting losses incurred as a result of the crisis itself. However, for now these profitability considerations remain beyond the scope of my study. 


